{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "0x7vDTwsDree",
        "outputId": "c71bf4a4-f8dd-43db-a7cd-46fbfafc5c27"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Step 1: Load MNIST data\n",
        "mnist = fetch_openml(\"mnist_784\", version=1)\n",
        "X, y = mnist[\"data\"].values, mnist[\"target\"].astype(int).values\n",
        "\n",
        "# Sample the dataset to speed up computation (Optional)\n",
        "X, y = X[:7000], y[:7000]\n",
        "\n",
        "# Split the dataset\n",
        "X_mnist_train, X_mnist_test, y_mnist_train, y_mnist_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "YZO97a8lGc7f",
        "outputId": "021a3bc9-f590-4656-899f-bb2f561739ba"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define function to plot a single digit\n",
        "def plot_digit(image_data):\n",
        "    image = image_data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "some_digit = X[3]\n",
        "plot_digit(some_digit)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxL0S7AWHQ8x",
        "outputId": "5d5e2639-9706-4e6f-f88a-a69871d70d7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "value: [1]\n",
            "accuracy: 0.8707142857142857\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "sgd_clf.fit(X_mnist_train, y_mnist_train)\n",
        "\n",
        "value = sgd_clf.predict([some_digit])\n",
        "\n",
        "print(f'value: {value}')\n",
        "\n",
        "\n",
        "y_predicted = sgd_clf.predict(X_mnist_test)\n",
        "accuracy = accuracy_score(y_mnist_test, y_predicted)\n",
        "print(f'accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u99MVF7H0do",
        "outputId": "d3f89e83-e36e-4890-f473-95551a1ac05c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.86073915, 0.87091591, 0.85048232])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Scikit learn makes it easy to use cross validation with simple measures\n",
        "# CV is the number of folds\n",
        "cross_val_score(sgd_clf, X_mnist_train, y_mnist_train, cv=3, scoring=\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL6EJJuBJecl"
      },
      "source": [
        "**To Turn In**\n",
        "\n",
        "Choose three different classifiers (not using any neural networks) and see which performs better on the dataset.  Please include code that cleanly demonstrates the three models you have attempted to use.\n",
        "\n",
        "**Rules:**\n",
        "1.  Ensure you compare them in consistent ways.\n",
        "2.  Ensure there is no data leakage between the training and test set.\n",
        "\n",
        "**Answer the following questions:**\n",
        "\n",
        "0. What data cleaning did you attempt to do?\n",
        "\n",
        "I performed exploratory data analysis (EDA) and did not find any need for data cleaning. There were no missing values or duplicates, and the classes appeared balanced.\n",
        "\n",
        "For data preprocessing, I used StandardScaler to normalize the data and Principal Component Analysis (PCA) to reduce the number of features and simplify the model.\n",
        "\n",
        "1. Which models did you try?  Include a link to the documentation for the model you are using.\n",
        "\n",
        "- Support Vector Classification https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
        "- Random Forest Classifier https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "- Logistic Regression CV https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\n",
        "\n",
        "\n",
        "2. Which hyperparamaters did you choose and why?\n",
        "\n",
        "- For SVC, I chose C, the regularization parameter, to control the trade-off between regularization strength and model performance.\n",
        "- For Random Forest, I chose n_estimators, the number of trees in the forest, to balance performance and computational costs.\n",
        "- For Logistic Regression, I selected the penalty parameter, using L1 (Lasso regularization), which could potentially help ignore background pixels that do not contribute to the classification task.\n",
        "\n",
        "\n",
        "3. How did you evaluate the models?  Which metric did you choose to use, why?\n",
        "\n",
        "I decided to look at all the metrics covered in class to understand their differences. Since the data is balanced, accuracy could be used alone, but I explored other metrics for deeper insight.\n",
        "\n",
        "- Accuracy: The ratio of correctly predicted instances to the total instances. (e.g., accuracy is 98% if the model correctly predicts 98 out of 100 digits.)\n",
        "- Precision: Measures how many of the predicted positive instances were actually positive. (e.g., precision is 80% if the model predicts 50 digits as a 3, but only 40 of them are actually 3s.)\n",
        "- Recall: Measures how many actual positive instances were correctly predicted by the model. (e.g., recall is 70% if the model correctly identifies 70 out of 100 examples of the digit 3.)\n",
        "- F1-Score: The harmonic mean of precision and recall. (e.g., if the model has a precision of 80% and recall of 70%, the F1-score will be around 74%.)\n",
        "- ROC-AUC: Measures the model’s performance across all classification thresholds.\n",
        "- Confusion Matrix: Provides a complete breakdown of the classification results, showing where the model is making correct predictions and where it’s making mistakes.\n",
        "\n",
        "4. How do you know your solution is not overfit or underfit?\n",
        "\n",
        "I used k-fold cross-validation to assess how well the model generalizes to unseen data. If the cross-validation results vary widely between folds or the training score is much higher than the cross-validation score, overfitting might be occurring. If both the training score and cross-validation score are low, the model is likely underfitting. In our case, the performance is high and stable, indicating that the models are neither overfitting nor underfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1vZWuJFOICW-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_mnist_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5, 7, 2, ..., 6, 9, 0])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_mnist_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(pd.DataFrame(X_mnist_train).isnull().sum().sum()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for duplicates\n",
        "num_duplicates = len(X_mnist_train) - len(np.unique(X_mnist_train, axis=0))\n",
        "num_duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGzCAYAAADJ3dZzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3/0lEQVR4nO3de1RVdf7/8dfhjiIgJudAKl5HxHuaetLMlJGMsRrN1KhITdc4mBcax5hKTVPLJq8Ral/TxiS7+NXKTMUbNoaXcCxTMy0nLD3gpIDSCAr798f8ON9OoAKiB/c8H2vttdyfz2fv/f7IEV7uGxbDMAwBAACYlIe7CwAAALieCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDtAFUydOlUWi+WGHKtXr17q1auXc3379u2yWCx6//33b8jxH3/8cTVu3PiGHKuqzp8/ryeeeEI2m00Wi0Xjx493d0k3lZvhawxcC8IO/ustX75cFovFufj5+Sk8PFwxMTFasGCBzp07Vy3HOXnypKZOnar9+/dXy/6qU02urSJmzpyp5cuXa/To0VqxYoUeffTRy45t3LixLBaLoqOjy+1//fXXnZ+Fzz//3NleGnCtVqt+/vnncvf7u9/9zqXNYrFozJgxLm2nT5/WuHHjFBkZKX9/f4WGhqpLly6aNGmSzp8/7wyzFVmuJj8/X88//7zat2+vgIAA+fv7q02bNpo0aZJOnjx51e0Bs/BydwFATTFt2jQ1adJEFy9elMPh0Pbt2zV+/HjNmTNHH374odq1a+cc++yzz+rpp5+u1P5Pnjyp559/Xo0bN1aHDh0qvN2mTZsqdZyquFJtr7/+ukpKSq57Dddi69at6tatm6ZMmVKh8X5+ftq2bZscDodsNptL38qVK+Xn56cLFy6Uu21OTo5SUlL01FNPVbrOM2fOqHPnzsrPz9fw4cMVGRmpn376SV9++aVSUlI0evRotWrVSitWrHDZLikpSQEBAXrmmWcqfKzvvvtO0dHRysrK0qBBgzRq1Cj5+Pjoyy+/1NKlS7VmzRp98803lZ4DcDMi7AD/X79+/dS5c2fnelJSkrZu3arf/e53uu+++3T48GH5+/tLkry8vOTldX3/+fz888+qVauWfHx8rutxrsbb29utx6+InJwcRUVFVXh89+7dtXfvXr3zzjsaN26cs/2HH37Qp59+qt///vdavXp1udt26NBBL7/8sv74xz86Pw8VtXTpUmVlZWnnzp264447XPry8/Pl4+MjPz8/PfLIIy59L774om655ZYy7Zdz6dIlDRgwQNnZ2dq+fbt69Ojh0j9jxgy99NJLlaoduJlxGQu4gt69e+u5557T999/r7feesvZXt49O2lpaerRo4eCg4MVEBCgli1b6i9/+Yuk/9xnc/vtt0uShg0b5rwMsXz5ckn/uS+nTZs2yszMVM+ePVWrVi3ntr++Z6dUcXGx/vKXv8hms6l27dq67777dOLECZcxjRs31uOPP15m21/u82q1lXc/R0FBgZ566ik1bNhQvr6+atmypf7617/KMAyXcaWXcdauXas2bdrI19dXrVu31oYNG8r/C/+VnJwcjRgxQlarVX5+fmrfvr3efPNNZ3/pJZ/jx4/r448/dtb+z3/+84r79fPz04ABA5SamurS/vbbb6tu3bqKiYm57LaTJ09Wdna2UlJSKjSHX/r222/l6empbt26lekLDAyUn59fpfdZntWrV+uLL77QM888UybolB5rxowZV9zHX//6V91xxx2qV6+e/P391alTp3LvE7vS577UwoUL1bp1a9WqVUt169ZV586dy/zd//jjjxo+fLisVqvzc/LGG2+UOV5F9gX8GmEHuIrS+z+udDnp4MGD+t3vfqfCwkJNmzZNr7zyiu677z7t3LlTktSqVStNmzZNkjRq1CitWLFCK1asUM+ePZ37+Omnn9SvXz916NBB8+bN0913333FumbMmKGPP/5YkyZN0tixY5WWlqbo6Gj9+9//rtT8KlLbLxmGofvuu09z587VPffcozlz5qhly5aaOHGiEhMTy4z/+9//rj/+8Y8aMmSIZs+erQsXLmjgwIH66aefrljXv//9b/Xq1UsrVqxQXFycXn75ZQUFBenxxx/X/PnznbWvWLFCt9xyizp06OCsvX79+led98MPP6w9e/bo22+/dbalpqbqwQcfvOLZrDvvvFO9e/fW7NmzK/13HRERoeLi4jKXqarbhx9+KElXvHfpaubPn6+OHTtq2rRpmjlzpry8vDRo0CB9/PHHzjFX+9xL/7kMOnbsWEVFRWnevHl6/vnn1aFDB+3evds5Jjs7W926ddPmzZs1ZswYzZ8/X82bN9eIESM0b968Su0LKJcB/JdbtmyZIcnYu3fvZccEBQUZHTt2dK5PmTLF+OU/n7lz5xqSjNOnT192H3v37jUkGcuWLSvTd9dddxmSjEWLFpXbd9dddznXt23bZkgybr31ViM/P9/Z/u677xqSjPnz5zvbIiIijPj4+Kvu80q1xcfHGxEREc71tWvXGpKMF154wWXcgw8+aFgsFuPYsWPONkmGj4+PS9sXX3xhSDIWLlxY5li/NG/ePEOS8dZbbznbioqKDLvdbgQEBLjMPSIiwoiNjb3i/n499tKlS4bNZjOmT59uGIZhHDp0yJBkpKenl/uZKP2anz592khPTzckGXPmzLliDZKMhIQE57rD4TDq169vSDIiIyONP/zhD0ZqaqqRm5t7xZpbt27t8vW6mo4dOxpBQUEVHv/rr7FhGMbPP//ssl5UVGS0adPG6N27t7OtIp/7+++/32jduvUVjz9ixAgjLCzM+Ne//uXSPmTIECMoKMhZS0X2BZSHMztABQQEBFzxqazg4GBJ0gcffFDlm3l9fX01bNiwCo9/7LHHVKdOHef6gw8+qLCwMK1fv75Kx6+o9evXy9PTU2PHjnVpf+qpp2QYhj755BOX9ujoaDVr1sy53q5dOwUGBuq777676nFsNpuGDh3qbPP29tbYsWN1/vx5paenX9M8PD099dBDD+ntt9+W9J8bkxs2bKg777zzqtv27NlTd999d6XP7litVn3xxRf6wx/+oLNnz2rRokV6+OGHFRoaqunTp5e5DFhV+fn5Lp+Nqvjl/Uhnz55VXl6e7rzzTu3bt8/ZXpHPfXBwsH744Qft3bu33H7DMLR69Wr1799fhmHoX//6l3OJiYlRXl6e85hX2xdwOYQdoALOnz9/xR8egwcPVvfu3fXEE0/IarVqyJAhevfddysVfG699dZK3YzcokULl3WLxaLmzZtf9X6Va/X9998rPDy8zN9Hq1atnP2/1KhRozL7qFu3rs6ePXvV47Ro0UIeHq7fpi53nKp4+OGHdejQIX3xxRdKTU3VkCFDKvz+pKlTp8rhcGjRokWVOmZYWJhSUlJ06tQpHTlyRAsWLFD9+vU1efJkLV26tCrTKCMwMPCaX5mwbt06devWTX5+fgoJCVH9+vWVkpKivLw855iKfO4nTZqkgIAAdenSRS1atFBCQoLLZa7Tp08rNzdXS5YsUf369V2W0vCfk5NToX0Bl0PYAa7ihx9+UF5enpo3b37ZMf7+/tqxY4c2b96sRx99VF9++aUGDx6s3/72tyouLq7QcSr7ZE9FXO4Hd0Vrqg6enp7ltlfXWYxr0bVrVzVr1kzjx4/X8ePH9fDDD1d42549e6pXr15VundH+s/X5je/+Y2efPJJ7dixQx4eHlq5cmWl91OeyMhI5eXllblhvaI+/fRT3XffffLz89Nrr72m9evXKy0tTQ8//LDL160in/tWrVrpyJEjWrVqlXr06KHVq1erR48eztcElAajRx55RGlpaeUu3bt3r9C+gMsh7ABXUXoz6ZWe0JEkDw8P9enTR3PmzNGhQ4c0Y8YMbd26Vdu2bZN0+eBRVUePHnVZNwxDx44dc3lyqm7dusrNzS2z7a/PilSmtoiICJ08ebLMmYOvv/7a2V8dIiIidPTo0TJnx6r7OEOHDtX27dvVqlWrSr3/SPq/szuLFy++phqaNm2qunXr6tSpU9e0n1L9+/eXJJcnCCtj9erV8vPz08aNGzV8+HD169fvsi9hvNrnXpJq166twYMHa9myZcrKylJsbKxmzJihCxcuqH79+qpTp46Ki4sVHR1d7hIaGlqhfQGXQ9gBrmDr1q2aPn26mjRpori4uMuOO3PmTJm20h+chYWFkv7zTVpSueGjKv72t7+5BI73339fp06dUr9+/ZxtzZo1065du1RUVORsW7duXZn/8VemtnvvvVfFxcV69dVXXdrnzp0ri8Xicvxrce+998rhcOidd95xtl26dEkLFy5UQECA7rrrrmo5zhNPPKEpU6bolVdeqfS2d911l3r16qWXXnqpQj9sd+/erYKCgjLte/bs0U8//aSWLVtWuobyPPjgg2rbtq1mzJihjIyMMv3nzp274gsKPT09ZbFYXM4A/vOf/9TatWtdxlXkc//rp+58fHwUFRUlwzB08eJFeXp6auDAgVq9erW++uqrMvs7ffq0889X2xdwObxUEPj/PvnkE3399de6dOmSsrOztXXrVqWlpSkiIkIffvjhFd+BMm3aNO3YsUOxsbGKiIhQTk6OXnvtNTVo0MD5npNmzZopODhYixYtUp06dVS7dm117dpVTZo0qVK9ISEh6tGjh4YNG6bs7GzNmzdPzZs318iRI51jnnjiCb3//vu655579NBDD+nbb7/VW2+95XLDcGVr69+/v+6++24988wz+uc//6n27dtr06ZN+uCDDzR+/Pgy+66qUaNGafHixXr88ceVmZmpxo0b6/3339fOnTs1b968a74Bt1RERISmTp1a5e2nTJly1dcElFqxYoVWrlyp3//+9+rUqZN8fHx0+PBhvfHGG/Lz8yvzfpqq8vb21v/+7/8qOjpaPXv21EMPPaTu3bvL29tbBw8eVGpqqurWrXvZd+3ExsZqzpw5uueee/Twww8rJydHycnJat68ub788kvnuIp87vv27Subzabu3bvLarXq8OHDevXVVxUbG+v8Gr744ovatm2bunbtqpEjRyoqKkpnzpzRvn37tHnzZmeoqsi+gHK57TkwoIYofcy4dPHx8TFsNpvx29/+1pg/f77LI86lfv3o+ZYtW4z777/fCA8PN3x8fIzw8HBj6NChxjfffOOy3QcffGBERUUZXl5eLo9633XXXZd9pPZyj56//fbbRlJSkhEaGmr4+/sbsbGxxvfff19m+1deecW49dZbDV9fX6N79+7G559/XmafV6qtvMeSz507Z0yYMMEIDw83vL29jRYtWhgvv/yyUVJS4jJOv3r0utTlHon/tezsbGPYsGHGLbfcYvj4+Bht27Yt9/H4qjx6fiVXe/T810pfHXC1R8+//PJLY+LEicZtt91mhISEGF5eXkZYWJgxaNAgY9++fZetp7KPnpc6e/asMXnyZKNt27ZGrVq1DD8/P6NNmzZGUlKScerUKee48r7GS5cuNVq0aGH4+voakZGRxrJly6r0uV+8eLHRs2dPo169eoavr6/RrFkzY+LEiUZeXp7L8bKzs42EhASjYcOGhre3t2Gz2Yw+ffoYS5YsqfS+gF+zGEYNuEsQAADgOuGeHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGqEHQAAYGq8VFD/+d0sJ0+eVJ06dar9lf4AAOD6MAxD586dU3h4eJlfGvxLhB1JJ0+eVMOGDd1dBgAAqIITJ06oQYMGl+0n7EjO14yfOHFCgYGBbq4GAABURH5+vho2bHjVXxdC2NH//cbnwMBAwg4AADeZq92Cwg3KAADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1LzcXQCur04T/+buEq4o8+XH3F0CAMDkOLMDAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMze1h58cff9QjjzyievXqyd/fX23bttXnn3/u7DcMQ5MnT1ZYWJj8/f0VHR2to0ePuuzjzJkziouLU2BgoIKDgzVixAidP3/+Rk8FAADUQG4NO2fPnlX37t3l7e2tTz75RIcOHdIrr7yiunXrOsfMnj1bCxYs0KJFi7R7927Vrl1bMTExunDhgnNMXFycDh48qLS0NK1bt047duzQqFGj3DElAABQw1gMwzDcdfCnn35aO3fu1Kefflpuv2EYCg8P11NPPaU//elPkqS8vDxZrVYtX75cQ4YM0eHDhxUVFaW9e/eqc+fOkqQNGzbo3nvv1Q8//KDw8PCr1pGfn6+goCDl5eUpMDCw+iZYA/CLQAHUdDX5+xTfo2q2iv78duuZnQ8//FCdO3fWoEGDFBoaqo4dO+r111939h8/flwOh0PR0dHOtqCgIHXt2lUZGRmSpIyMDAUHBzuDjiRFR0fLw8NDu3fvLve4hYWFys/Pd1kAAIA5uTXsfPfdd0pJSVGLFi20ceNGjR49WmPHjtWbb74pSXI4HJIkq9Xqsp3VanX2ORwOhYaGuvR7eXkpJCTEOebXZs2apaCgIOfSsGHD6p4aAACoIdwadkpKSnTbbbdp5syZ6tixo0aNGqWRI0dq0aJF1/W4SUlJysvLcy4nTpy4rscDAADu49awExYWpqioKJe2Vq1aKSsrS5Jks9kkSdnZ2S5jsrOznX02m005OTku/ZcuXdKZM2ecY37N19dXgYGBLgsAADAnt4ad7t2768iRIy5t33zzjSIiIiRJTZo0kc1m05YtW5z9+fn52r17t+x2uyTJbrcrNzdXmZmZzjFbt25VSUmJunbtegNmAQAAajIvdx58woQJuuOOOzRz5kw99NBD2rNnj5YsWaIlS5ZIkiwWi8aPH68XXnhBLVq0UJMmTfTcc88pPDxcDzzwgKT/nAm65557nJe/Ll68qDFjxmjIkCEVehILAACYm1vDzu233641a9YoKSlJ06ZNU5MmTTRv3jzFxcU5x/z5z39WQUGBRo0apdzcXPXo0UMbNmyQn5+fc8zKlSs1ZswY9enTRx4eHho4cKAWLFjgjikBAIAaxq3v2akpeM+O+/AOCwA1+fsU36NqtpviPTsAAADXG2EHAACYGmEHAACYGmEHAACYGmEHAACYGmEHAACYGmEHAACYmltfKgj8N6nJ7xKReJ8IAPPizA4AADA1wg4AADA1LmMBqBQux9UcfC2AiuHMDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDXCDgAAMDVeKngFNfmFXbysCwBQ3Wryzz2p6j/7OLMDAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjffsAABwjcz6fhqz4MwOAAAwNcIOAAAwNcIOAAAwNe7ZwU2hJl8P/2+/Fg4ANR1ndgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKkRdgAAgKm5NexMnTpVFovFZYmMjHT2X7hwQQkJCapXr54CAgI0cOBAZWdnu+wjKytLsbGxqlWrlkJDQzVx4kRdunTpRk8FAADUUF7uLqB169bavHmzc93L6/9KmjBhgj7++GO99957CgoK0pgxYzRgwADt3LlTklRcXKzY2FjZbDZ99tlnOnXqlB577DF5e3tr5syZN3wuAACg5nF72PHy8pLNZivTnpeXp6VLlyo1NVW9e/eWJC1btkytWrXSrl271K1bN23atEmHDh3S5s2bZbVa1aFDB02fPl2TJk3S1KlT5ePjc6OnAwAAahi337Nz9OhRhYeHq2nTpoqLi1NWVpYkKTMzUxcvXlR0dLRzbGRkpBo1aqSMjAxJUkZGhtq2bSur1eocExMTo/z8fB08ePCyxywsLFR+fr7LAgAAzMmtYadr165avny5NmzYoJSUFB0/flx33nmnzp07J4fDIR8fHwUHB7tsY7Va5XA4JEkOh8Ml6JT2l/ZdzqxZsxQUFORcGjZsWL0TAwAANYZbL2P169fP+ed27dqpa9euioiI0Lvvvit/f//rdtykpCQlJiY61/Pz8wk8AACYlNsvY/1ScHCwfvOb3+jYsWOy2WwqKipSbm6uy5js7GznPT42m63M01ml6+XdB1TK19dXgYGBLgsAADCnGhV2zp8/r2+//VZhYWHq1KmTvL29tWXLFmf/kSNHlJWVJbvdLkmy2+06cOCAcnJynGPS0tIUGBioqKioG14/AACoedx6GetPf/qT+vfvr4iICJ08eVJTpkyRp6enhg4dqqCgII0YMUKJiYkKCQlRYGCgnnzySdntdnXr1k2S1LdvX0VFRenRRx/V7Nmz5XA49OyzzyohIUG+vr7unBoAAKgh3Bp2fvjhBw0dOlQ//fST6tevrx49emjXrl2qX7++JGnu3Lny8PDQwIEDVVhYqJiYGL322mvO7T09PbVu3TqNHj1adrtdtWvXVnx8vKZNm+auKQEAgBrGrWFn1apVV+z38/NTcnKykpOTLzsmIiJC69evr+7SAACASdSoe3YAAACqG2EHAACYGmEHAACYGmEHAACYGmEHAACYGmEHAACYGmEHAACYmlvfswMA7tJp4t/cXcJlZb78mLtLAEyFMzsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUCDsAAMDUakzYefHFF2WxWDR+/Hhn24ULF5SQkKB69eopICBAAwcOVHZ2tst2WVlZio2NVa1atRQaGqqJEyfq0qVLN7h6AABQU9WIsLN3714tXrxY7dq1c2mfMGGCPvroI7333ntKT0/XyZMnNWDAAGd/cXGxYmNjVVRUpM8++0xvvvmmli9frsmTJ9/oKQAAgBrK7WHn/PnziouL0+uvv666des62/Py8rR06VLNmTNHvXv3VqdOnbRs2TJ99tln2rVrlyRp06ZNOnTokN566y116NBB/fr10/Tp05WcnKyioqLLHrOwsFD5+fkuCwAAMCe3h52EhATFxsYqOjrapT0zM1MXL150aY+MjFSjRo2UkZEhScrIyFDbtm1ltVqdY2JiYpSfn6+DBw9e9pizZs1SUFCQc2nYsGE1zwoAANQUbg07q1at0r59+zRr1qwyfQ6HQz4+PgoODnZpt1qtcjgczjG/DDql/aV9l5OUlKS8vDzncuLEiWucCQAAqKm83HXgEydOaNy4cUpLS5Ofn98NPbavr698fX1v6DEBAIB7uO3MTmZmpnJycnTbbbfJy8tLXl5eSk9P14IFC+Tl5SWr1aqioiLl5ua6bJednS2bzSZJstlsZZ7OKl0vHQMAAP67uS3s9OnTRwcOHND+/fudS+fOnRUXF+f8s7e3t7Zs2eLc5siRI8rKypLdbpck2e12HThwQDk5Oc4xaWlpCgwMVFRU1A2fEwAAqHncdhmrTp06atOmjUtb7dq1Va9ePWf7iBEjlJiYqJCQEAUGBurJJ5+U3W5Xt27dJEl9+/ZVVFSUHn30Uc2ePVsOh0PPPvusEhISuEwFAAAkuTHsVMTcuXPl4eGhgQMHqrCwUDExMXrttdec/Z6enlq3bp1Gjx4tu92u2rVrKz4+XtOmTXNj1QAAoCapUWFn+/btLut+fn5KTk5WcnLyZbeJiIjQ+vXrr3NlAADgZuX29+wAAABcT4QdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgaoQdAABgalUKO71791Zubm6Z9vz8fPXu3ftaawIAAKg2VQo727dvV1FRUZn2Cxcu6NNPP73mogAAAKqLV2UGf/nll84/Hzp0SA6Hw7leXFysDRs26NZbb62+6gAAAK5RpcJOhw4dZLFYZLFYyr1c5e/vr4ULF1ZbcQAAANeqUmHn+PHjMgxDTZs21Z49e1S/fn1nn4+Pj0JDQ+Xp6VntRQIAAFRVpcJORESEJKmkpOS6FAMAAFDdKhV2funo0aPatm2bcnJyyoSfyZMnX3NhAAAA1aFKYef111/X6NGjdcstt8hms8lisTj7LBYLYQcAANQYVQo7L7zwgmbMmKFJkyZVdz0AAADVqkrv2Tl79qwGDRpU3bUAAABUuyqFnUGDBmnTpk3VXQsAAEC1q9JlrObNm+u5557Trl271LZtW3l7e7v0jx07tlqKAwAAuFZVCjtLlixRQECA0tPTlZ6e7tJnsVgIOwAAoMaoUtg5fvx4ddcBAABwXVTpnh0AAICbRZXO7AwfPvyK/W+88UaVigEAAKhuVQo7Z8+edVm/ePGivvrqK+Xm5pb7C0IBAADcpUphZ82aNWXaSkpKNHr0aDVr1uyaiwIAAKgu1XbPjoeHhxITEzV37tzq2iUAAMA1q9YblL/99ltdunSpOncJAABwTap0GSsxMdFl3TAMnTp1Sh9//LHi4+OrpTAAAIDqUKWw849//MNl3cPDQ/Xr19crr7xy1Se1AAAAbqQqhZ1t27ZVdx0AAADXRZXCTqnTp0/ryJEjkqSWLVuqfv361VIUAABAdanSDcoFBQUaPny4wsLC1LNnT/Xs2VPh4eEaMWKEfv755+quEQAAoMqqFHYSExOVnp6ujz76SLm5ucrNzdUHH3yg9PR0PfXUU9VdIwAAQJVV6TLW6tWr9f7776tXr17OtnvvvVf+/v566KGHlJKSUl31AQAAXJMqndn5+eefZbVay7SHhoZyGQsAANQoVQo7drtdU6ZM0YULF5xt//73v/X888/LbrdXW3EAAADXqkphZ968edq5c6caNGigPn36qE+fPmrYsKF27typ+fPnV3g/KSkpateunQIDAxUYGCi73a5PPvnE2X/hwgUlJCSoXr16CggI0MCBA5Wdne2yj6ysLMXGxqpWrVoKDQ3VxIkTeYszAABwqtI9O23bttXRo0e1cuVKff3115KkoUOHKi4uTv7+/hXeT4MGDfTiiy+qRYsWMgxDb775pu6//3794x//UOvWrTVhwgR9/PHHeu+99xQUFKQxY8ZowIAB2rlzpySpuLhYsbGxstls+uyzz3Tq1Ck99thj8vb21syZM6syNQAAYDJVCjuzZs2S1WrVyJEjXdrfeOMNnT59WpMmTarQfvr37++yPmPGDKWkpGjXrl1q0KCBli5dqtTUVPXu3VuStGzZMrVq1Uq7du1St27dtGnTJh06dEibN2+W1WpVhw4dNH36dE2aNElTp06Vj49PVaYHAABMpEqXsRYvXqzIyMgy7a1bt9aiRYuqVEhxcbFWrVqlgoIC2e12ZWZm6uLFi4qOjnaOiYyMVKNGjZSRkSFJysjIUNu2bV1ulo6JiVF+fr4OHjx42WMVFhYqPz/fZQEAAOZUpbDjcDgUFhZWpr1+/fo6depUpfZ14MABBQQEyNfXV3/4wx+0Zs0aRUVFyeFwyMfHR8HBwS7jrVarHA6Hs45fPxVWul46pjyzZs1SUFCQc2nYsGGlagYAADePKoWd0puRf23nzp0KDw+v1L5atmyp/fv3a/fu3Ro9erTi4+N16NChqpRVYUlJScrLy3MuJ06cuK7HAwAA7lOle3ZGjhyp8ePH6+LFi877abZs2aI///nPlX6Dso+Pj5o3by5J6tSpk/bu3av58+dr8ODBKioqUm5ursvZnezsbNlsNkmSzWbTnj17XPZX+rRW6Zjy+Pr6ytfXt1J1AgCAm1OVws7EiRP1008/6Y9//KOKiookSX5+fpo0aZKSkpKuqaCSkhIVFhaqU6dO8vb21pYtWzRw4EBJ0pEjR5SVleV8l4/dbteMGTOUk5Oj0NBQSVJaWpoCAwMVFRV1TXUAAABzqFLYsVgseumll/Tcc8/p8OHD8vf3V4sWLSp9tiQpKUn9+vVTo0aNdO7cOaWmpmr79u3auHGjgoKCNGLECCUmJiokJESBgYF68sknZbfb1a1bN0lS3759FRUVpUcffVSzZ8+Ww+HQs88+q4SEBM7cAAAASVUMO6UCAgJ0++23V3n7nJwcPfbYYzp16pSCgoLUrl07bdy4Ub/97W8lSXPnzpWHh4cGDhyowsJCxcTE6LXXXnNu7+npqXXr1mn06NGy2+2qXbu24uPjNW3atGuZFgAAMJFrCjvXaunSpVfs9/PzU3JyspKTky87JiIiQuvXr6/u0gAAgElU6WksAACAmwVhBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmJpbw86sWbN0++23q06dOgoNDdUDDzygI0eOuIy5cOGCEhISVK9ePQUEBGjgwIHKzs52GZOVlaXY2FjVqlVLoaGhmjhxoi5dunQjpwIAAGoot4ad9PR0JSQkaNeuXUpLS9PFixfVt29fFRQUOMdMmDBBH330kd577z2lp6fr5MmTGjBggLO/uLhYsbGxKioq0meffaY333xTy5cv1+TJk90xJQAAUMN4ufPgGzZscFlfvny5QkNDlZmZqZ49eyovL09Lly5VamqqevfuLUlatmyZWrVqpV27dqlbt27atGmTDh06pM2bN8tqtapDhw6aPn26Jk2apKlTp8rHx8cdUwMAADVEjbpnJy8vT5IUEhIiScrMzNTFixcVHR3tHBMZGalGjRopIyNDkpSRkaG2bdvKarU6x8TExCg/P18HDx4s9ziFhYXKz893WQAAgDnVmLBTUlKi8ePHq3v37mrTpo0kyeFwyMfHR8HBwS5jrVarHA6Hc8wvg05pf2lfeWbNmqWgoCDn0rBhw2qeDQAAqClqTNhJSEjQV199pVWrVl33YyUlJSkvL8+5nDhx4rofEwAAuIdb79kpNWbMGK1bt047duxQgwYNnO02m01FRUXKzc11ObuTnZ0tm83mHLNnzx6X/ZU+rVU65td8fX3l6+tbzbMAAAA1kVvP7BiGoTFjxmjNmjXaunWrmjRp4tLfqVMneXt7a8uWLc62I0eOKCsrS3a7XZJkt9t14MAB5eTkOMekpaUpMDBQUVFRN2YiAACgxnLrmZ2EhASlpqbqgw8+UJ06dZz32AQFBcnf319BQUEaMWKEEhMTFRISosDAQD355JOy2+3q1q2bJKlv376KiorSo48+qtmzZ8vhcOjZZ59VQkICZ28AAIB7w05KSookqVevXi7ty5Yt0+OPPy5Jmjt3rjw8PDRw4EAVFhYqJiZGr732mnOsp6en1q1bp9GjR8tut6t27dqKj4/XtGnTbtQ0AABADebWsGMYxlXH+Pn5KTk5WcnJyZcdExERofXr11dnaQAAwCRqzNNYAAAA1wNhBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmBphBwAAmJpbw86OHTvUv39/hYeHy2KxaO3atS79hmFo8uTJCgsLk7+/v6Kjo3X06FGXMWfOnFFcXJwCAwMVHBysESNG6Pz58zdwFgAAoCZza9gpKChQ+/btlZycXG7/7NmztWDBAi1atEi7d+9W7dq1FRMTowsXLjjHxMXF6eDBg0pLS9O6deu0Y8cOjRo16kZNAQAA1HBe7jx4v3791K9fv3L7DMPQvHnz9Oyzz+r++++XJP3tb3+T1WrV2rVrNWTIEB0+fFgbNmzQ3r171blzZ0nSwoULde+99+qvf/2rwsPDb9hcAABAzVRj79k5fvy4HA6HoqOjnW1BQUHq2rWrMjIyJEkZGRkKDg52Bh1Jio6OloeHh3bv3n3ZfRcWFio/P99lAQAA5lRjw47D4ZAkWa1Wl3ar1ersczgcCg0Nden38vJSSEiIc0x5Zs2apaCgIOfSsGHDaq4eAADUFDU27FxPSUlJysvLcy4nTpxwd0kAAOA6qbFhx2azSZKys7Nd2rOzs519NptNOTk5Lv2XLl3SmTNnnGPK4+vrq8DAQJcFAACYU40NO02aNJHNZtOWLVucbfn5+dq9e7fsdrskyW63Kzc3V5mZmc4xW7duVUlJibp27XrDawYAADWPW5/GOn/+vI4dO+ZcP378uPbv36+QkBA1atRI48eP1wsvvKAWLVqoSZMmeu655xQeHq4HHnhAktSqVSvdc889GjlypBYtWqSLFy9qzJgxGjJkCE9iAQAASW4OO59//rnuvvtu53piYqIkKT4+XsuXL9ef//xnFRQUaNSoUcrNzVWPHj20YcMG+fn5ObdZuXKlxowZoz59+sjDw0MDBw7UggULbvhcAABAzeTWsNOrVy8ZhnHZfovFomnTpmnatGmXHRMSEqLU1NTrUR4AADCBGnvPDgAAQHUg7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMj7AAAAFMzTdhJTk5W48aN5efnp65du2rPnj3uLgkAANQApgg777zzjhITEzVlyhTt27dP7du3V0xMjHJyctxdGgAAcDNThJ05c+Zo5MiRGjZsmKKiorRo0SLVqlVLb7zxhrtLAwAAbubl7gKuVVFRkTIzM5WUlORs8/DwUHR0tDIyMsrdprCwUIWFhc71vLw8SVJ+fr7LuOLCf1+HiqvHr2u9nJo8B8kc8zDDHCTmUZOYYQ6SOeZhhjlI5p1H6bphGFfe0LjJ/fjjj4Yk47PPPnNpnzhxotGlS5dyt5kyZYohiYWFhYWFhcUEy4kTJ66YFW76MztVkZSUpMTEROd6SUmJzpw5o3r16slisVT78fLz89WwYUOdOHFCgYGB1b7/G4V51BxmmINkjnmYYQ4S86hJzDAH6cbMwzAMnTt3TuHh4Vccd9OHnVtuuUWenp7Kzs52ac/OzpbNZit3G19fX/n6+rq0BQcHX68SnQIDA2/qD24p5lFzmGEOkjnmYYY5SMyjJjHDHKTrP4+goKCrjrnpb1D28fFRp06dtGXLFmdbSUmJtmzZIrvd7sbKAABATXDTn9mRpMTERMXHx6tz587q0qWL5s2bp4KCAg0bNszdpQEAADczRdgZPHiwTp8+rcmTJ8vhcKhDhw7asGGDrFaru0uT9J/LZlOmTClz6exmwzxqDjPMQTLHPMwwB4l51CRmmINUs+ZhMYyrPa8FAABw87rp79kBAAC4EsIOAAAwNcIOAAAwNcIOAAAwNcIOAAAwNcLODZCcnKzGjRvLz89PXbt21Z49e9xdUqXs2LFD/fv3V3h4uCwWi9auXevukipt1qxZuv3221WnTh2FhobqgQce0JEjR9xdVqWlpKSoXbt2zjeS2u12ffLJJ+4u65q8+OKLslgsGj9+vLtLqZSpU6fKYrG4LJGRke4uq0p+/PFHPfLII6pXr578/f3Vtm1bff755+4uq8IaN25c5mthsViUkJDg7tIqpbi4WM8995yaNGkif39/NWvWTNOnT7/6L7msYc6dO6fx48crIiJC/v7+uuOOO7R371631kTYuc7eeecdJSYmasqUKdq3b5/at2+vmJgY5eTkuLu0CisoKFD79u2VnJzs7lKqLD09XQkJCdq1a5fS0tJ08eJF9e3bVwUFBe4urVIaNGigF198UZmZmfr888/Vu3dv3X///Tp48KC7S6uSvXv3avHixWrXrp27S6mS1q1b69SpU87l73//u7tLqrSzZ8+qe/fu8vb21ieffKJDhw7plVdeUd26dd1dWoXt3bvX5euQlpYmSRo0aJCbK6ucl156SSkpKXr11Vd1+PBhvfTSS5o9e7YWLlzo7tIq5YknnlBaWppWrFihAwcOqG/fvoqOjtaPP/7ovqKq5VeP47K6dOliJCQkONeLi4uN8PBwY9asWW6squokGWvWrHF3GdcsJyfHkGSkp6e7u5RrVrduXeN//ud/3F1GpZ07d85o0aKFkZaWZtx1113GuHHj3F1SpUyZMsVo3769u8u4ZpMmTTJ69Ojh7jKq1bhx44xmzZoZJSUl7i6lUmJjY43hw4e7tA0YMMCIi4tzU0WV9/PPPxuenp7GunXrXNpvu+0245lnnnFTVYbBmZ3rqKioSJmZmYqOjna2eXh4KDo6WhkZGW6sDHl5eZKkkJAQN1dSdcXFxVq1apUKCgpuyt8Dl5CQoNjYWJd/Hzebo0ePKjw8XE2bNlVcXJyysrLcXVKlffjhh+rcubMGDRqk0NBQdezYUa+//rq7y6qyoqIivfXWWxo+fLgsFou7y6mUO+64Q1u2bNE333wjSfriiy/097//Xf369XNzZRV36dIlFRcXy8/Pz6Xd39/frWc+TfHrImqqf/3rXyouLi7zayusVqu+/vprN1WFkpISjR8/Xt27d1ebNm3cXU6lHThwQHa7XRcuXFBAQIDWrFmjqKgod5dVKatWrdK+ffvcfh3/WnTt2lXLly9Xy5YtderUKT3//PO688479dVXX6lOnTruLq/CvvvuO6WkpCgxMVF/+ctftHfvXo0dO1Y+Pj6Kj493d3mVtnbtWuXm5urxxx93dymV9vTTTys/P1+RkZHy9PRUcXGxZsyYobi4OHeXVmF16tSR3W7X9OnT1apVK1mtVr399tvKyMhQ8+bN3VYXYQf/dRISEvTVV1/dlPdXSFLLli21f/9+5eXl6f3331d8fLzS09NvmsBz4sQJjRs3TmlpaWX+93cz+eX/ttu1a6euXbsqIiJC7777rkaMGOHGyiqnpKREnTt31syZMyVJHTt21FdffaVFixbdlGFn6dKl6tevn8LDw91dSqW9++67WrlypVJTU9W6dWvt379f48ePV3h4+E31tVixYoWGDx+uW2+9VZ6enrrttts0dOhQZWZmuq0mws51dMstt8jT01PZ2dku7dnZ2bLZbG6q6r/bmDFjtG7dOu3YsUMNGjRwdzlV4uPj4/wfUqdOnbR3717Nnz9fixcvdnNlFZOZmamcnBzddtttzrbi4mLt2LFDr776qgoLC+Xp6enGCqsmODhYv/nNb3Ts2DF3l1IpYWFhZYJyq1attHr1ajdVVHXff/+9Nm/erP/93/91dylVMnHiRD399NMaMmSIJKlt27b6/vvvNWvWrJsq7DRr1kzp6ekqKChQfn6+wsLCNHjwYDVt2tRtNXHPznXk4+OjTp06acuWLc62kpISbdmy5aa8x+JmZhiGxowZozVr1mjr1q1q0qSJu0uqNiUlJSosLHR3GRXWp08fHThwQPv373cunTt3VlxcnPbv339TBh1JOn/+vL799luFhYW5u5RK6d69e5nXMHzzzTeKiIhwU0VVt2zZMoWGhio2NtbdpVTJzz//LA8P1x/Lnp6eKikpcVNF16Z27doKCwvT2bNntXHjRt1///1uq4UzO9dZYmKi4uPj1blzZ3Xp0kXz5s1TQUGBhg0b5u7SKuz8+fMu/1s9fvy49u/fr5CQEDVq1MiNlVVcQkKCUlNT9cEHH6hOnTpyOBySpKCgIPn7+7u5uopLSkpSv3791KhRI507d06pqanavn27Nm7c6O7SKqxOnTpl7pWqXbu26tWrd1PdQ/WnP/1J/fv3V0REhE6ePKkpU6bI09NTQ4cOdXdplTJhwgTdcccdmjlzph566CHt2bNHS5Ys0ZIlS9xdWqWUlJRo2bJlio+Pl5fXzfmjrX///poxY4YaNWqk1q1b6x//+IfmzJmj4cOHu7u0Stm4caMMw1DLli117NgxTZw4UZGRke79uee258D+iyxcuNBo1KiR4ePjY3Tp0sXYtWuXu0uqlG3bthmSyizx8fHuLq3CyqtfkrFs2TJ3l1Ypw4cPNyIiIgwfHx+jfv36Rp8+fYxNmza5u6xrdjM+ej548GAjLCzM8PHxMW699VZj8ODBxrFjx9xdVpV89NFHRps2bQxfX18jMjLSWLJkibtLqrSNGzcakowjR464u5Qqy8/PN8aNG2c0atTI8PPzM5o2bWo888wzRmFhobtLq5R33nnHaNq0qeHj42PYbDYjISHByM3NdWtNFsO4yV7NCAAAUAncswMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEzt/wF+QscZ6/NzzAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check the distribution of target classes (digits)\n",
        "sns.countplot(x=y_mnist_train)\n",
        "plt.title('Distribution of MNIST Classes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5600.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5600.000000</td>\n",
              "      <td>5600.000000</td>\n",
              "      <td>5600.000000</td>\n",
              "      <td>5600.000000</td>\n",
              "      <td>5600.000000</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.225179</td>\n",
              "      <td>0.137143</td>\n",
              "      <td>0.075714</td>\n",
              "      <td>0.061250</td>\n",
              "      <td>0.060179</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6.488715</td>\n",
              "      <td>4.412283</td>\n",
              "      <td>4.002542</td>\n",
              "      <td>2.788938</td>\n",
              "      <td>2.737315</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>254.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>187.000000</td>\n",
              "      <td>154.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0       1       2       3       4       5       6       7       8    \\\n",
              "count  5600.0  5600.0  5600.0  5600.0  5600.0  5600.0  5600.0  5600.0  5600.0   \n",
              "mean      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "std       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "min       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "25%       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "50%       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "75%       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "max       0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
              "\n",
              "          9    ...          774          775          776          777  \\\n",
              "count  5600.0  ...  5600.000000  5600.000000  5600.000000  5600.000000   \n",
              "mean      0.0  ...     0.225179     0.137143     0.075714     0.061250   \n",
              "std       0.0  ...     6.488715     4.412283     4.002542     2.788938   \n",
              "min       0.0  ...     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.0  ...     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.0  ...     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.0  ...     0.000000     0.000000     0.000000     0.000000   \n",
              "max       0.0  ...   254.000000   254.000000   253.000000   187.000000   \n",
              "\n",
              "               778     779     780     781     782     783  \n",
              "count  5600.000000  5600.0  5600.0  5600.0  5600.0  5600.0  \n",
              "mean      0.060179     0.0     0.0     0.0     0.0     0.0  \n",
              "std       2.737315     0.0     0.0     0.0     0.0     0.0  \n",
              "min       0.000000     0.0     0.0     0.0     0.0     0.0  \n",
              "25%       0.000000     0.0     0.0     0.0     0.0     0.0  \n",
              "50%       0.000000     0.0     0.0     0.0     0.0     0.0  \n",
              "75%       0.000000     0.0     0.0     0.0     0.0     0.0  \n",
              "max     154.000000     0.0     0.0     0.0     0.0     0.0  \n",
              "\n",
              "[8 rows x 784 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(X_mnist_train).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the classifiers with pipelines\n",
        "\n",
        "pipelines = {\n",
        "    \"SVC\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('pca', PCA(n_components=0.95)),\n",
        "        ('svc', SVC(probability=True, random_state=42, C=1.5))\n",
        "    ]),\n",
        "    \"RandomForest\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('pca', PCA(n_components=0.95)),\n",
        "        ('rf', RandomForestClassifier(random_state=42, n_estimators=200))\n",
        "    ]),\n",
        "    \"LogisticRegression\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('pca', PCA(n_components=0.95)),\n",
        "        ('lr', LogisticRegression(max_iter=1000, random_state=42, penalty='l1', solver='liblinear'))\n",
        "    ])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and evaluate each pipeline\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, pipeline in pipelines.items():\n",
        "    pipeline.fit(X_mnist_train, y_mnist_train)\n",
        "    \n",
        "    # Predictions on the test set\n",
        "    y_pred = pipeline.predict(X_mnist_test)\n",
        "    \n",
        "    # Evaluate the model using various metrics\n",
        "    accuracy = accuracy_score(y_mnist_test, y_pred)\n",
        "    precision = precision_score(y_mnist_test, y_pred, average='macro')\n",
        "    recall = recall_score(y_mnist_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_mnist_test, y_pred, average='macro')\n",
        "    roc_auc = roc_auc_score(y_mnist_test, pipeline.predict_proba(X_mnist_test), multi_class='ovr')\n",
        "    confusion = confusion_matrix(y_mnist_test, y_pred)\n",
        "    \n",
        "    # Save results\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"confusion_matrix\": confusion\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.9485714285714286,\n",
              " 'precision': np.float64(0.9486636403762925),\n",
              " 'recall': np.float64(0.9469782983142915),\n",
              " 'f1_score': np.float64(0.9475267985119024),\n",
              " 'roc_auc': np.float64(0.9976103477680056),\n",
              " 'confusion_matrix': array([[135,   0,   1,   0,   0,   0,   1,   0,   1,   0],\n",
              "        [  0, 157,   1,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  2,   0, 134,   2,   1,   0,   0,   1,   1,   1],\n",
              "        [  0,   1,   6, 125,   0,   4,   1,   1,   2,   1],\n",
              "        [  0,   1,   2,   0, 140,   0,   0,   0,   0,   3],\n",
              "        [  1,   1,   1,   2,   0, 125,   3,   1,   0,   0],\n",
              "        [  0,   0,   4,   0,   0,   1, 134,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   1,   0,   0, 147,   0,   2],\n",
              "        [  1,   0,   2,   2,   0,   4,   0,   1, 101,   0],\n",
              "        [  1,   1,   0,   2,   1,   0,   0,   5,   1, 130]])}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results['SVC']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.915,\n",
              " 'precision': np.float64(0.9137984004086237),\n",
              " 'recall': np.float64(0.9120153981689763),\n",
              " 'f1_score': np.float64(0.9121862193945628),\n",
              " 'roc_auc': np.float64(0.9928802239574971),\n",
              " 'confusion_matrix': array([[130,   0,   0,   3,   0,   1,   3,   0,   1,   0],\n",
              "        [  0, 158,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  1,   1, 124,   6,   1,   0,   3,   2,   3,   1],\n",
              "        [  0,   0,   9, 125,   0,   1,   1,   1,   3,   1],\n",
              "        [  0,   2,   2,   0, 135,   1,   1,   0,   0,   5],\n",
              "        [  1,   0,   2,  10,   0, 109,   0,   0,   9,   3],\n",
              "        [  1,   0,   1,   0,   1,   1, 135,   0,   0,   0],\n",
              "        [  0,   0,   0,   1,   2,   0,   0, 145,   0,   2],\n",
              "        [  1,   0,   2,   7,   2,   3,   0,   1,  95,   0],\n",
              "        [  3,   1,   0,   2,   2,   0,   0,   6,   2, 125]])}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results['RandomForest']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.9007142857142857,\n",
              " 'precision': np.float64(0.8997980450985539),\n",
              " 'recall': np.float64(0.8978974211778379),\n",
              " 'f1_score': np.float64(0.8981375319425832),\n",
              " 'roc_auc': np.float64(0.9856958882058008),\n",
              " 'confusion_matrix': array([[130,   0,   0,   1,   0,   0,   4,   1,   2,   0],\n",
              "        [  0, 156,   1,   0,   0,   0,   0,   0,   1,   0],\n",
              "        [  2,   1, 119,   3,   2,   2,   1,   7,   4,   1],\n",
              "        [  1,   2,   7, 117,   1,   5,   2,   1,   2,   3],\n",
              "        [  0,   2,   1,   1, 131,   0,   2,   0,   2,   7],\n",
              "        [  1,   2,   1,   5,   1, 114,   2,   2,   4,   2],\n",
              "        [  0,   0,   1,   0,   2,   2, 134,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   1,   0,   0, 145,   0,   4],\n",
              "        [  1,   3,   1,   4,   3,   3,   1,   1,  93,   1],\n",
              "        [  0,   0,   1,   3,   1,   1,   0,  12,   1, 122]])}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results['LogisticRegression']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cross-Validation Scores for SVC: [0.93035714 0.93660714 0.93303571 0.93303571 0.925     ]\n",
            "Mean CV Score: 0.9316\n",
            "\n",
            "Cross-Validation Scores for RandomForest: [0.90803571 0.91339286 0.90714286 0.89464286 0.90178571]\n",
            "Mean CV Score: 0.9050\n",
            "\n",
            "Cross-Validation Scores for LogisticRegression: [0.89642857 0.88660714 0.90982143 0.90535714 0.88214286]\n",
            "Mean CV Score: 0.8961\n"
          ]
        }
      ],
      "source": [
        "for name, pipeline in pipelines.items():\n",
        "    cv_scores = cross_val_score(pipeline, X_mnist_train, y_mnist_train, cv=5)\n",
        "    print(f\"\\nCross-Validation Scores for {name}: {cv_scores}\")\n",
        "    print(f\"Mean CV Score: {cv_scores.mean():.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
